{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Gathering</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    TagUI for Web Automation:\n",
    "    - Collect posts from Linkedin By CATEGORY using #__nameOfCategory__\n",
    "    - Save data as .csv format\n",
    "'''\n",
    " #start headless automation\n",
    "#t.init(visual_automation=False)\n",
    "#start visual automation\n",
    "t.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#providing links for the posts of each category\n",
    "urls=['https://www.linkedin.com/feed/hashtag/intelligenceartificielle/','https://www.linkedin.com/feed/hashtag/bigdata/','https://www.linkedin.com/feed/hashtag/iot/','https://www.linkedin.com/feed/hashtag/digitalbanking/','https://www.linkedin.com/feed/hashtag/outsourcing/','https://www.linkedin.com/feed/hashtag/mobile/','https://www.linkedin.com/feed/hashtag/agility/','https://www.linkedin.com/feed/hashtag/digitalfactory/','https://www.linkedin.com/feed/hashtag/omnichannelmarketing/','https://www.linkedin.com/feed/hashtag/omnichannelretail/','https://www.linkedin.com/feed/hashtag/startup/','https://www.linkedin.com/feed/hashtag/projectmanagement/','https://www.linkedin.com/feed/hashtag/transformationdigitale/','https://www.linkedin.com/feed/hashtag/digitaltransformation/','https://www.linkedin.com/feed/hashtag/digitalfinance/','https://www.linkedin.com/feed/hashtag/fintech/','https://www.linkedin.com/feed/hashtag/insurtech/','https://www.linkedin.com/feed/hashtag/egov/','https://www.linkedin.com/feed/hashtag/egovernment','https://www.linkedin.com/feed/hashtag/egovernance/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts4=[]\n",
    "#collect the urls of the existing articles if it exists else 'no'\n",
    "article_urls4=[]\n",
    "#categories of the current posts, we take it from the current url\n",
    "tags4=[]\n",
    "\n",
    "for url in urls:\n",
    "    t.url(url)\n",
    "    #print('Collect posts from  ',url)\n",
    "    #j for post's article, if there is an article in the current post its value will be incremented \n",
    "    j=0\n",
    "    #k for shared post\"s article, if there is an article in the current shared post its value will be incremented \n",
    "    k=0\n",
    "    t.wait(5)\n",
    "\n",
    "    #handle exception: when you are signed out\n",
    "    if t.url()==\"https://www.linkedin.com/m/login/\":\n",
    "        t.url('https://www.linkedin.com/uas/login?session_redirect=%2Fvoyager%2FloginRedirect%2Ehtml&fromSignIn=true&trk=uno-reg-join-sign-in')\n",
    "        t.type('username','abir.korched@ensi-uma.tn')\n",
    "        t.type('password','**********')\n",
    "        t.click('Sign in')\n",
    "        t.url(url)\n",
    "        t.wait(10)\n",
    "\n",
    "    #scroll down and collect posts until there is no new loaded post\n",
    "    for i in range(1,300):\n",
    "        #scroll down to load more posts\n",
    "        t.dom('window.scrollBy(0, 2000)')\n",
    "        #read i-th post's content into txt\n",
    "        txt=t.read('(//*[@class=\"relative ember-view\"])['+str(i)+']')\n",
    "        #if the posts exists, check if there is an article (get its url if it exists)\n",
    "        if ''!=txt:\n",
    "            #print('post numéro :',i)\n",
    "            #if there is an article, save its href\n",
    "            if t.present('(//*[@class=\"relative ember-view\"])['+str(i)+']/div/div/article'):\n",
    "                #print(\"take the href of the article :\")\n",
    "                #print(j)\n",
    "                article_url=t.dom('return document.querySelectorAll(\"div.relative.ember-view div div article div div a\")['+str(j)+'].getAttribute(\"href\")')\n",
    "                #save post's content, the url of the existant article and the category\n",
    "                posts4.append(txt)\n",
    "                article_urls4.append(article_url)\n",
    "                tags4.append(url.split('/')[5])\n",
    "                #increment j for the next article\n",
    "                j+=2\n",
    "            #get the href of the shared post's article if it exists\n",
    "            elif t.present('(//*[@class=\"relative ember-view\"])['+str(i)+']/div/div/div/div/article'):\n",
    "                #print(k)\n",
    "                article_url=t.dom('return document.querySelectorAll(\"div.relative.ember-view div div div div article div div a\")['+str(k)+'].getAttribute(\"href\")')\n",
    "                #save post's content, the url of the existant article and the category\n",
    "                posts4.append(txt)\n",
    "                article_urls4.append(article_url)\n",
    "                tags4.append(url.split('/')[5])\n",
    "                #increment k for the next shared article\n",
    "                k+=2\n",
    "            else:\n",
    "                #there is no article in the post, so article_url='no'\n",
    "                #save post's content and the category\n",
    "                posts4.append(txt)\n",
    "                article_urls4.append('no')\n",
    "                tags4.append(url.split('/')[5])\n",
    "        else:\n",
    "            #no more loaded posts\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect data using two keywords\n",
    "urls=['https://www.linkedin.com/search/results/content/?keywords=%23vente%20%23distribution&origin=SWITCH_SEARCH_VERTICAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    t.url(url)\n",
    "    #print('Collect posts from  ',url)\n",
    "    #j for post's article, if there is an article in the current post its value will be incremented \n",
    "    j=0\n",
    "    #k for shared post\"s article, if there is an article in the current shared post its value will be incremented \n",
    "    k=0\n",
    "    t.wait(5)\n",
    "\n",
    "    #handle exception: when you are signed out\n",
    "    if t.url()==\"https://www.linkedin.com/m/login/\":\n",
    "        t.url('https://www.linkedin.com/uas/login?session_redirect=%2Fvoyager%2FloginRedirect%2Ehtml&fromSignIn=true&trk=uno-reg-join-sign-in')\n",
    "        #connect to linkedin account\n",
    "        #type the email\n",
    "        t.type('username','***.******@proxym-group.com')\n",
    "        #type password\n",
    "        t.type('password','**********')\n",
    "        t.click('Sign in')\n",
    "        t.url(url)\n",
    "        t.wait(10)\n",
    "\n",
    "    #scroll down and collect posts until there is no new loaded post\n",
    "    for i in range(1,300):\n",
    "        #scroll down to load more posts\n",
    "        t.dom('window.scrollBy(0, 2000)')\n",
    "        #read i-th post's content into txt\n",
    "        txt=t.read('(//*[@class=\"search-content__result search-entity ember-view\"])['+str(i)+']')\n",
    "        #if the posts exists, check if there is an article (get its url if it exists)\n",
    "        if ''!=txt:\n",
    "            #print('post numéro :',i)\n",
    "            #if there is an article, save its href\n",
    "            if t.present('(//*[@class=\"search-content__result search-entity ember-view\"])['+str(i)+']/div/article'):\n",
    "                #print(\"take the href of the article :\")\n",
    "                #print(j)\n",
    "                article_url=t.dom('return document.querySelectorAll(\"li.search-content__result.search-entity.ember-view div article.feed-shared-update-v2__content div div a\")['+str(j)+'].getAttribute(\"href\")')\n",
    "                #save post's content, the url of the existant article and the category\n",
    "                posts4.append(txt)\n",
    "                article_urls4.append(article_url)\n",
    "                tags4.append(url.split('/')[5])\n",
    "                #increment j for the next article\n",
    "                j+=2\n",
    "            else:\n",
    "                #there is no article in the post, so article_url='no'\n",
    "                #save post's content and the category\n",
    "                posts4.append(txt)\n",
    "                article_urls4.append('no')\n",
    "                tags4.append('ventedistribution')\n",
    "        else:\n",
    "            #no more loaded posts\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get article content by looping over article_urls4\n",
    "article_content=[]\n",
    "#i=0\n",
    "for url in article_urls4:\n",
    "    #print('numéro  :'+str(i))\n",
    "    #i+=1\n",
    "    if url!='no' and 'docs.google.com' not in url and '.pdf' not in url:\n",
    "        t.url(url)\n",
    "        t.wait(random.choice(range(3,6)))\n",
    "        txt=t.read(\"page\")\n",
    "        if 'ERR_NAME_NOT_RESOLVED' not in txt and 'ERR_CERT_DATE_INVALID' not in txt and 'XML file does not appear' not in txt:\n",
    "            article_content.append(txt)\n",
    "        else:\n",
    "            #site can't be reached\n",
    "            article_content.append('no')\n",
    "    else:\n",
    "        article_content.append('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#END of Automation\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save posts in .csv format\n",
    "import pandas as pd\n",
    "info={\n",
    "    'post':posts4,\n",
    "    'category':tags4,\n",
    "    'article_content':article_content}\n",
    "df= pd.DataFrame(info,columns=['post','category','article_content'])\n",
    "df.to_csv(\"dataset_linkedinposts.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>category</th>\n",
       "      <th>article_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IKOMOBI\\n      \\n    \\n\\n      \\n        1,431...</td>\n",
       "      <td>digitalfactory</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Status is offline\\n  \\n\\n\\n\\n\\n      \\n    \\n\\...</td>\n",
       "      <td>digitalfactory</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Status is offline\\n  \\n\\n\\n\\n\\n      \\n    \\n\\...</td>\n",
       "      <td>digitalfactory</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;\\n        &lt;!-- Google Tag Manager ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Status is offline\\n  \\n\\n\\n\\n\\n      \\n    \\n\\...</td>\n",
       "      <td>digitalfactory</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Status is offline\\n  \\n\\n\\n\\n\\n      \\n    \\n\\...</td>\n",
       "      <td>digitalfactory</td>\n",
       "      <td>&lt;html lang=\"fr\"&gt;&lt;head&gt;\\n\\t&lt;title&gt;Coca-Cola acc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post        category  \\\n",
       "0  IKOMOBI\\n      \\n    \\n\\n      \\n        1,431...  digitalfactory   \n",
       "1  Status is offline\\n  \\n\\n\\n\\n\\n      \\n    \\n\\...  digitalfactory   \n",
       "2  Status is offline\\n  \\n\\n\\n\\n\\n      \\n    \\n\\...  digitalfactory   \n",
       "3  Status is offline\\n  \\n\\n\\n\\n\\n      \\n    \\n\\...  digitalfactory   \n",
       "4  Status is offline\\n  \\n\\n\\n\\n\\n      \\n    \\n\\...  digitalfactory   \n",
       "\n",
       "                                     article_content  \n",
       "0                                                 no  \n",
       "1                                                 no  \n",
       "2  <html><head>\\n        <!-- Google Tag Manager ...  \n",
       "3                                                 no  \n",
       "4  <html lang=\"fr\"><head>\\n\\t<title>Coca-Cola acc...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3833, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
